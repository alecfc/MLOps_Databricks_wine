{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3534047,"sourceType":"datasetVersion","datasetId":2125691}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T08:03:14.392932Z","iopub.execute_input":"2023-09-21T08:03:14.393436Z","iopub.status.idle":"2023-09-21T08:03:14.403556Z","shell.execute_reply.started":"2023-09-21T08:03:14.393388Z","shell.execute_reply":"2023-09-21T08:03:14.402289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Image](http://https://www.realsimple.com/thmb/5GPNGPLNH228wa7jUJ2HPpaRBao=/750x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/red-wine-health-benefits-ce3be96b730b41cc82f128abb75c2395.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"**What to Expect?**\n** **\nIn this notebook, I will explore the Spanish Wine Quality Dataset and fit a regression model on the price column. I will use Scikit-Learn, Pandas, Numpy, Seaborn and Matplotlib.pyplot in this notebook\n\n","metadata":{}},{"cell_type":"markdown","source":"**Attribute Information**\n** **\nwinery: Winery name\nwine: Name of the wine\nyear: Year in which the grapes were harvested\nrating: Average rating given to the wine by the users [from 1-5]\nnum_reviews: Number of users that reviewed the wine\ncountry: Country of origin [Spain]\nregion: Region of the wine\nprice: Price in euros [€]\ntype: Wine variety\nbody: Body score, defined as the richness and weight of the wine in your mouth [from 1-5]\nacidity: Acidity score, defined as wine's “pucker” or tartness; it's what makes a wine refreshing and your tongue salivate and want another sip [from 1-5]","metadata":{}},{"cell_type":"markdown","source":"**If you are not understanding any line of my code just copy paste on chatgpt to gat a detailed understanding on that lne of code.**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.405662Z","iopub.execute_input":"2023-09-21T08:03:14.406237Z","iopub.status.idle":"2023-09-21T08:03:14.421685Z","shell.execute_reply.started":"2023-09-21T08:03:14.406205Z","shell.execute_reply":"2023-09-21T08:03:14.420602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/spanish-wine-quality-dataset/wines_SPA.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.423831Z","iopub.execute_input":"2023-09-21T08:03:14.424622Z","iopub.status.idle":"2023-09-21T08:03:14.472738Z","shell.execute_reply.started":"2023-09-21T08:03:14.424567Z","shell.execute_reply":"2023-09-21T08:03:14.471612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.474557Z","iopub.execute_input":"2023-09-21T08:03:14.475492Z","iopub.status.idle":"2023-09-21T08:03:14.482986Z","shell.execute_reply.started":"2023-09-21T08:03:14.475454Z","shell.execute_reply":"2023-09-21T08:03:14.481712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**so we have**\n* **rows-7500**\n* **columns-11**","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.484593Z","iopub.execute_input":"2023-09-21T08:03:14.485497Z","iopub.status.idle":"2023-09-21T08:03:14.509311Z","shell.execute_reply.started":"2023-09-21T08:03:14.485459Z","shell.execute_reply":"2023-09-21T08:03:14.50843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see that there are some operations is needed in null values and the Dtype also ","metadata":{}},{"cell_type":"markdown","source":"Statistical Analysis","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.511262Z","iopub.execute_input":"2023-09-21T08:03:14.511806Z","iopub.status.idle":"2023-09-21T08:03:14.547737Z","shell.execute_reply.started":"2023-09-21T08:03:14.511773Z","shell.execute_reply":"2023-09-21T08:03:14.546603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(100*(df.isnull().sum()/df.shape[0]), 2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.558903Z","iopub.execute_input":"2023-09-21T08:03:14.56002Z","iopub.status.idle":"2023-09-21T08:03:14.576725Z","shell.execute_reply.started":"2023-09-21T08:03:14.559977Z","shell.execute_reply":"2023-09-21T08:03:14.575456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets first see our columns in detailed manner**","metadata":{}},{"cell_type":"code","source":"def val(x):\n  for column in x.columns:\n    print(\"{}:{},\".format(column,x[column].unique()))\n    print(\"        \")\n    print(\"        \")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.578974Z","iopub.execute_input":"2023-09-21T08:03:14.579327Z","iopub.status.idle":"2023-09-21T08:03:14.585836Z","shell.execute_reply.started":"2023-09-21T08:03:14.579299Z","shell.execute_reply":"2023-09-21T08:03:14.584595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.587358Z","iopub.execute_input":"2023-09-21T08:03:14.587951Z","iopub.status.idle":"2023-09-21T08:03:14.620898Z","shell.execute_reply.started":"2023-09-21T08:03:14.587915Z","shell.execute_reply":"2023-09-21T08:03:14.619596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see we are able to see all columns in detail with there unique values.\nSo now we can do operations as per our requirement.**","metadata":{}},{"cell_type":"code","source":"#lets first drop all null values\ndf=df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.622727Z","iopub.execute_input":"2023-09-21T08:03:14.624769Z","iopub.status.idle":"2023-09-21T08:03:14.638335Z","shell.execute_reply.started":"2023-09-21T08:03:14.624719Z","shell.execute_reply":"2023-09-21T08:03:14.637228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.642795Z","iopub.execute_input":"2023-09-21T08:03:14.643585Z","iopub.status.idle":"2023-09-21T08:03:14.663727Z","shell.execute_reply.started":"2023-09-21T08:03:14.643538Z","shell.execute_reply":"2023-09-21T08:03:14.662398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now as we see above in year column we have one unique value as \"N.V.\" lets replace it with nan and drop\n#it with dropna \ndf[\"year\"]=df[\"year\"].replace(\"N.V.\",np.NaN)\ndf=df.dropna()\ndf['year'] = df['year'].astype(np.int64)\nprint(df.year.unique())","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.666036Z","iopub.execute_input":"2023-09-21T08:03:14.666554Z","iopub.status.idle":"2023-09-21T08:03:14.687868Z","shell.execute_reply.started":"2023-09-21T08:03:14.666507Z","shell.execute_reply":"2023-09-21T08:03:14.686471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we see in the above step we first converted that N.V. value to na and then dropped it.\nAfter that we converted our str to int**","metadata":{}},{"cell_type":"code","source":"#Country column is not important so lets drop it\ndf=df.drop(\"country\",axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.689829Z","iopub.execute_input":"2023-09-21T08:03:14.690286Z","iopub.status.idle":"2023-09-21T08:03:14.711877Z","shell.execute_reply.started":"2023-09-21T08:03:14.690242Z","shell.execute_reply":"2023-09-21T08:03:14.710617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"markdown","source":"**Lets see how the attributes are correlated with price**","metadata":{}},{"cell_type":"code","source":"df2=df.drop([\"winery\",\"wine\",\"region\",\"type\"],axis=1)\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.713395Z","iopub.execute_input":"2023-09-21T08:03:14.713779Z","iopub.status.idle":"2023-09-21T08:03:14.731857Z","shell.execute_reply.started":"2023-09-21T08:03:14.71375Z","shell.execute_reply":"2023-09-21T08:03:14.730453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df2.corr(),annot=True,cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:14.735283Z","iopub.execute_input":"2023-09-21T08:03:14.736284Z","iopub.status.idle":"2023-09-21T08:03:15.23061Z","shell.execute_reply.started":"2023-09-21T08:03:14.736249Z","shell.execute_reply":"2023-09-21T08:03:15.229376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Oooh seems like most of our numerical variables does not have much of a correlation on the price column except for the rating that has a weak to moderate positive correlation. The price and rating column has a positive correlation which means that when the rating is high, its more likely that the price is also high, which make sense (but not in all cases).**","metadata":{}},{"cell_type":"markdown","source":"**Does the type of the wine affects the wines price?**","metadata":{}},{"cell_type":"code","source":"#lets check\nplt.bar(df[\"type\"],df[\"price\"])\nplt.xticks(rotation=90)\nplt.xlabel(\"Type of wine\")\nplt.ylabel(\"Price in euros [€]\")\nplt.title(\"price VS Type \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:15.232061Z","iopub.execute_input":"2023-09-21T08:03:15.232423Z","iopub.status.idle":"2023-09-21T08:03:26.097861Z","shell.execute_reply.started":"2023-09-21T08:03:15.232375Z","shell.execute_reply":"2023-09-21T08:03:26.096673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we see some has high price and some doesnt so it means that wines price vary depending on the type of wine.**","metadata":{}},{"cell_type":"markdown","source":"# Data Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nprint(\"categorical Variables:\")\nfor col in df.columns:\n    if df[col].dtype==\"object\":\n        print(str(col))\n        label=LabelEncoder()\n        label=label.fit(df[col])\n        df[col]=label.transform(df[col].astype(str))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.099518Z","iopub.execute_input":"2023-09-21T08:03:26.099883Z","iopub.status.idle":"2023-09-21T08:03:26.122729Z","shell.execute_reply.started":"2023-09-21T08:03:26.099853Z","shell.execute_reply":"2023-09-21T08:03:26.121312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.12428Z","iopub.execute_input":"2023-09-21T08:03:26.125201Z","iopub.status.idle":"2023-09-21T08:03:26.150643Z","shell.execute_reply.started":"2023-09-21T08:03:26.125164Z","shell.execute_reply":"2023-09-21T08:03:26.149318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.152256Z","iopub.execute_input":"2023-09-21T08:03:26.152655Z","iopub.status.idle":"2023-09-21T08:03:26.172519Z","shell.execute_reply.started":"2023-09-21T08:03:26.152623Z","shell.execute_reply":"2023-09-21T08:03:26.171302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now every thing is converted into numerical values so we can standardization here**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit and transform the scaler on the DataFrame\ndf_standardized = scaler.fit_transform(df)\n\n# Convert the result back to a DataFrame (optional)\ndf_std = pd.DataFrame(df_standardized, columns=df.columns)\ndf_std.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.177005Z","iopub.execute_input":"2023-09-21T08:03:26.177355Z","iopub.status.idle":"2023-09-21T08:03:26.202619Z","shell.execute_reply.started":"2023-09-21T08:03:26.177327Z","shell.execute_reply":"2023-09-21T08:03:26.201465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"X=df_std.drop(\"price\",axis=1)\ny=df_std[[\"price\"]]\ny = y.values.ravel()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.20409Z","iopub.execute_input":"2023-09-21T08:03:26.204562Z","iopub.status.idle":"2023-09-21T08:03:26.211481Z","shell.execute_reply.started":"2023-09-21T08:03:26.204529Z","shell.execute_reply":"2023-09-21T08:03:26.210379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.212792Z","iopub.execute_input":"2023-09-21T08:03:26.21314Z","iopub.status.idle":"2023-09-21T08:03:26.230166Z","shell.execute_reply.started":"2023-09-21T08:03:26.21311Z","shell.execute_reply":"2023-09-21T08:03:26.228876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_std.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.231942Z","iopub.execute_input":"2023-09-21T08:03:26.232445Z","iopub.status.idle":"2023-09-21T08:03:26.250802Z","shell.execute_reply.started":"2023-09-21T08:03:26.23238Z","shell.execute_reply":"2023-09-21T08:03:26.249224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.252002Z","iopub.execute_input":"2023-09-21T08:03:26.252519Z","iopub.status.idle":"2023-09-21T08:03:26.259881Z","shell.execute_reply.started":"2023-09-21T08:03:26.252467Z","shell.execute_reply":"2023-09-21T08:03:26.258597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.261931Z","iopub.execute_input":"2023-09-21T08:03:26.262388Z","iopub.status.idle":"2023-09-21T08:03:26.274481Z","shell.execute_reply.started":"2023-09-21T08:03:26.262346Z","shell.execute_reply":"2023-09-21T08:03:26.273343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Initialize and train regression models\nmodels = [\n    (\"Linear Regression\", LinearRegression()),\n    (\"Lasso Regression\", Lasso(alpha=0.01)),\n    (\"Ridge Regression\", Ridge(alpha=1.0)),\n    (\"Bayesian Ridge\", BayesianRidge()),\n    (\"Decision Tree Regressor\", DecisionTreeRegressor(random_state=42)),\n    (\"Linear SVR\", LinearSVR()),\n    (\"K-Nearest Neighbors Regressor\", KNeighborsRegressor(n_neighbors=5)),\n    (\"Random Forest Regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n]\n\n# Initialize a list to store results\nresults = []\n\n# Fit and evaluate each model\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    results.append([name, mse, r2])\n\n# Create a DataFrame from the results list\nresults_df = pd.DataFrame(results, columns=[\"Model\", \"Mean Squared Error\", \"R-squared\"])\n\n# Find the model with the lowest MSE and highest R-squared\nbest_mse_model = results_df.loc[results_df[\"Mean Squared Error\"].idxmin()]\nbest_r2_model = results_df.loc[results_df[\"R-squared\"].idxmax()]\n\nprint(\"Model Evaluation Results:\")\nprint(results_df)\nprint(\"\\nBest model based on MSE:\")\nprint(best_mse_model)\nprint(\"\\nBest model based on R-squared:\")\nprint(best_r2_model)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:26.275786Z","iopub.execute_input":"2023-09-21T08:03:26.276111Z","iopub.status.idle":"2023-09-21T08:03:27.812159Z","shell.execute_reply.started":"2023-09-21T08:03:26.276084Z","shell.execute_reply":"2023-09-21T08:03:27.810963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see above that Best model based on MSE: and Best model based on R-squared:**","metadata":{}},{"cell_type":"markdown","source":"**we can pick as per our requirement**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(110,50))\nplt.plot(y_pred,label='predicted')\nplt.plot(y_test,label='Actual')\nplt.legend(fontsize='large')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:27.813984Z","iopub.execute_input":"2023-09-21T08:03:27.81449Z","iopub.status.idle":"2023-09-21T08:03:31.385805Z","shell.execute_reply.started":"2023-09-21T08:03:27.814447Z","shell.execute_reply":"2023-09-21T08:03:31.384725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_std.corr(),annot=True,cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:03:31.387214Z","iopub.execute_input":"2023-09-21T08:03:31.388258Z","iopub.status.idle":"2023-09-21T08:03:32.112024Z","shell.execute_reply.started":"2023-09-21T08:03:31.388218Z","shell.execute_reply":"2023-09-21T08:03:32.11071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see the predicted values are close to actual values and some places it isnt due to our attributes or variables are not much correlated to the price**","metadata":{}},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"**The model does it job but not particularly good nor bad. But personally its kinda predictable that our model would do bad as how we saw that most columns has a very little to no relationship toward to the wines prices.**\n\n**Surprisingly though, our model did alright at predicting low prices wines but did terrible at high prices wines, I think what caused this from happening according to our EDA earlier, that in our dataset, theres way more data on low prices wines but theres a little data from the high price wines.**","metadata":{}},{"cell_type":"markdown","source":"# Authors Message\n* If you find this helpful, I would really appreciate the upvote!\n* If you see something wrong please let me know.\n* And lastly Im happy to hear your thoughts about the notebook for me to also improve!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}